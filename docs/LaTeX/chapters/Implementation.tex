\section{Implementation}

The implementation of the algorithm was carried out using C, inspired by the Python code provided in \cite{Azizi2023ParallelEM}.
The parallelization was achieved using MPI to enable distributed computing across multiple processors, and hybrid parallelization was implemented by combining MPI with OpenMP to leverage multi-threading within each process.
Subsequently, the code was expanded with additional Python and Bash scripts to better validate and analyse the performance of our implementation.

\subsubsection*{Data generation}
We generated synthetic datasets in Python to produce GMM-distributed data points, allowing full control over key characteristics such as the number of clusters, dimensionality, and number of samples. 
The generator also provided metadata about the generated samples, along with the true labels for each data point. 

\subsubsection*{Accuracy Checks}
As part of the implementation, we included validation checks to ensure the correctness of the algorithm, especially in the initial stages.
These checks involved comparing the outputs of the algorithm against the real labels provided by the data generator.
To perform this evaluation, we utilized permutation-invariant accuracy metrics (Hungarian algorithm), which allowed us to assess the clustering performance without being affected by the arbitrary ordering of cluster labels.
By resolving label permutations, we could accurately measure how well the algorithm clustered the data points according to their true underlying distributions.

\subsection{Parallel Algorithm Implementation}

\subsubsection*{Data distribution}
The dataset, together with its metadata, is initially loaded by the root process (rank 0).
First, the metadata (number of samples, dimensions, and number of clusters) is broadcast to all processes using \emph{MPI\_Bcast}.
Once the metadata is known, each process computes the size of its local data chunk, which is then used to distribute the dataset across processes via \emph{MPI\_Scatterv}. 
After receiving their respective chunks, all processes proceed with the computation.

At the end of the execution (specifically after the clustering assignment step) each process holds the predicted labels for its local data chunk.
These local predicted labels are gathered back to the root process using \emph{MPI\_Gatherv}, in order to be written back to a file for accuracy evaluation.

\subsubsection*{E-step Implementation}
As said before, the parallelization of the E-step doesn't involve any change in the sequential algorithm.
The only notable difference, is that we compute the log-likelihood for the convergence check inside the E-step itself, in order to avoid additional computation.

\subsubsection*{M-step Implementation}


\subsection{Hybrid Parallel Algorithm Implementation}